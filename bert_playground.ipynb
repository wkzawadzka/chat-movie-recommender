{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from django.db import models\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Strategries():\n",
    "\n",
    "    def bert():\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieID                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                            overview  \n",
      "0  Led by Woody, Andy's toys live happily in his ...  \n",
      "1  When siblings Judy and Peter discover an encha...  \n",
      "2  A family wedding reignites the ancient feud be...  \n",
      "3  Cheated on, mistreated and stepped on, the wom...  \n",
      "4  Just when George Banks has recovered from his ...  \n"
     ]
    }
   ],
   "source": [
    "PLOTS_DATA = os.path.join(\"backend-django\", \"data\", \"movies.csv\")\n",
    "# overviews\n",
    "plots = pd.read_csv(PLOTS_DATA).dropna()\n",
    "print(plots.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\weraz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download en_core_web_sm\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting bert embeddings...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from typing import List\n",
    "import torch\n",
    "\n",
    "class BERT_strategy:\n",
    "    ''' Movie recommendation strategy based on BERT model - High-performance semantic similarity\n",
    "    Works by finding similarities between movies' overviews:\n",
    "        (1) creating tokens out of each overviews\n",
    "        (2) sending tokanized overviews though BERT model\n",
    "        (3) choice of recommendation according to cosine similarity score between model outputs\n",
    "    '''\n",
    "    def __init__(self, movies: pd.DataFrame, cache_dir: str = './data/') -> None:\n",
    "        # ensure cache dir exists\n",
    "        self.cache_dir = cache_dir\n",
    "        os.makedirs(self.cache_dir, exist_ok=True)\n",
    "\n",
    "        self.model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\", cache_dir=self.cache_dir)\n",
    "        self.tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', cache_dir=self.cache_dir)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            # add tokenizer\n",
    "            self.tokenizer.add_special_tokens({'pad_token': 'EOS'}) # end of sentence token\n",
    "            self.model.resize_token_embeddings(len(self.tokenizer))\n",
    "        self.df = movies\n",
    "        self.overviews = [self.preprocess_string(str(a)) for a in self.df['overview'].values.tolist()]\n",
    "        \n",
    "        print(\"Getting bert embeddings...\")\n",
    "        embeddings_path = os.path.join(self.cache_dir, 'overviews_embeddings.pt')\n",
    "        if not os.path.exists(embeddings_path):\n",
    "            self.overviews_embeddings = self.model_outputs(self.overviews)\n",
    "            torch.save(self.overviews_embeddings, embeddings_path)\n",
    "        else:\n",
    "            self.overviews_embeddings = torch.load(embeddings_path)\n",
    "        print(\"Done\")\n",
    "            \n",
    "    def preprocess_string(self, text: str):\n",
    "        doc = nlp(text)\n",
    "        cleaned_text = ' '.join([token.lemma_ for token in doc if token.text.lower() not in stop_words and token.is_alpha])\n",
    "        \n",
    "        return cleaned_text\n",
    "\n",
    "    def model_outputs(self, items: List[str], batch_size: int = 64):\n",
    "        all_outputs = []\n",
    "        num_batches = len(items) // batch_size + (len(items) % batch_size != 0)\n",
    "        \n",
    "        for i in tqdm(range(0, len(items), batch_size), desc=\"Progress\", total=num_batches):\n",
    "            batch_items = items[i:i+batch_size]\n",
    "            inputs = self.tokenizer(batch_items, add_special_tokens=True, padding=True, max_length=100, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**inputs).last_hidden_state[:, 0, :].numpy()  # [batch, maxlen, hidden_state] -> using only [batch, hidden_state]\n",
    "                all_outputs.append(outputs)\n",
    "        \n",
    "        return np.concatenate(all_outputs, axis=0)\n",
    "\n",
    "    def recommend(self, query: str, k: int = 5):\n",
    "        '''         \n",
    "        @inputs\n",
    "            query: string, description of movie you seek for\n",
    "        @outputs\n",
    "            recommendation: list of top k movies with highest similarity score\n",
    "        '''\n",
    "        query_embedding = self.model_outputs([self.preprocess_string(query)])\n",
    "        sim = cosine_similarity(query_embedding, self.overviews_embeddings)[0]\n",
    "\n",
    "        movie_ids = self.df['movieID'].values.tolist()\n",
    "        top_k_indicies = sim.argsort()[-k:][::-1].tolist()\n",
    "\n",
    "        return [movie_ids[i] for i in top_k_indicies]\n",
    "    \n",
    "bert = BERT_strategy(plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 1/1 [00:00<00:00, 12.99it/s]\n"
     ]
    }
   ],
   "source": [
    "out_ids = bert.recommend(\"Amy begins her first night shift in a hotel with a murderous past. Witnessing terrifying events and trapped within a loop, Amy must find a way to escape the flesh obsessed murderer and save residents of the hotel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2518, 1053, 2298, 1996, 987]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Bliss (1997)',\n",
       "        'A mind-bending love story following Greg who, after recently being divorced and then fired, meets the mysterious Isabel, a woman living on the streets and convinced that the polluted, broken world around them is just a computer simulation. Doubtful at first, Greg eventually discovers there may be some truth to Isabel’s wild conspiracy.'],\n",
       "       ['Normal Life (1996)',\n",
       "        \"Chris Anderson and his wife Pam live a fairly normal life until Chris loses his job on the police force and secretly turns to robbing banks to make his wife's dreams come true. Upon discovering his secret, she joins his deadly crime wave and together they terrorize an unsuspecting suburban town.\"],\n",
       "       ['Poltergeist III (1988)',\n",
       "        \"Carol Anne has been sent to live with her Aunt and Uncle in an effort to hide her from the clutches of the ghostly Reverend Kane, but he tracks her down and terrorises her in her relatives' appartment in a tall glass building. Will he finally achieve his target and capture Carol Anne again, or will Tangina be able, yet again, to thwart him?\"],\n",
       "       ['Strangeland (1998)',\n",
       "        \"A pierced and tattooed sadist, Captain Howdy, trolls the Internet for naive teens, luring them to his home to torture and defile them. When Howdy kidnaps and tortures the daughter of police Detective Mike Gage, he is caught. Deemed insane, he is sent to an asylum but is released soon after, seemingly better. However, Gage knows it is only a matter of time before Howdy strikes again, and he's ready to unleash his own form of retribution when the time comes.\"],\n",
       "       ['Night Shift (1982)',\n",
       "        'Amy begins her first night shift in a hotel with a murderous past. Witnessing terrifying events and trapped within a loop, Amy must find a way to escape the flesh obsessed murderer and save residents of the hotel.']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots[plots['movieID'].isin(out_ids)][['title', 'overview']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 'Toy Story (1995)',\n",
       "        \"Led by Woody, Andy's toys live happily in his room until Andy's birthday brings Buzz Lightyear onto the scene. Afraid of losing his place in Andy's heart, Woody plots against Buzz. But when circumstances separate Buzz and Woody from their owner, the duo eventually learns to put aside their differences.\"],\n",
       "       [3114, 'Toy Story 2 (1999)',\n",
       "        \"Andy heads off to Cowboy Camp, leaving his toys to their own devices. Things shift into high gear when an obsessive toy collector named Al McWhiggen, owner of Al's Toy Barn kidnaps Woody. Andy's toys mount a daring rescue mission, Buzz Lightyear meets his match and Woody has to decide where he and his heart truly belong.\"]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plots[plots['title'].str.startswith('Toy Story')].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3771"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(plots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
